(window.webpackJsonp=window.webpackJsonp||[]).push([[48],{328:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"ts抽取组件描述"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ts抽取组件描述"}},[t._v("#")]),t._v(" TS抽取组件描述")]),t._v(" "),s("h2",{attrs:{id:"背景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#背景"}},[t._v("#")]),t._v(" 背景")]),t._v(" "),s("p",[t._v("低代码入料部分，玩的"),s("a",{attrs:{href:"https://www.yuque.com/lce/doc/yhgcqb",target:"_blank",rel:"noopener noreferrer"}},[t._v("花样"),s("OutboundLink")],1),t._v("很多，手动编写低代码组件描述，或者通过 ReactProps 语法识别，或者通过 Typescript 注释识别。其中，通过 Typescript 识别的部分则是基于 "),s("a",{attrs:{href:"https://github.com/styleguidist/react-docgen-typescript",target:"_blank",rel:"noopener noreferrer"}},[t._v("react-docgen-typescript"),s("OutboundLink")],1),t._v(" (以下简称 RDT )来实现的。另外，dumi 的"),s("a",{attrs:{href:"https://d.umijs.org/zh-CN/guide/advanced#%E7%BB%84%E4%BB%B6-api-%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90",target:"_blank",rel:"noopener noreferrer"}},[t._v("文档生成"),s("OutboundLink")],1),t._v("实际上也是通过 RDT 来实现的，包括 "),s("a",{attrs:{href:"https://github.com/doczjs/docz/tree/main/core",target:"_blank",rel:"noopener noreferrer"}},[t._v("docz"),s("OutboundLink")],1),t._v(" （现在的还有很多其他知名或不知名的足 ts 扫描多是基于 RDT）。\n而这个 RDT 实际上并没有预想中的那么强大，只是有限的识别了一部分 ast 范式。我在实际使用这个库的过程中踩了不少它的坑。它的问题包括但不限于：")]),t._v(" "),s("ol",[s("li",[t._v("不支持深层级的类型声明 "),s("a",{attrs:{href:"https://github.com/styleguidist/react-docgen-typescript/issues/202",target:"_blank",rel:"noopener noreferrer"}},[t._v("issue202"),s("OutboundLink")],1)]),t._v(" "),s("li",[t._v("不支持组件以外的 ts 文档生成 "),s("a",{attrs:{href:"https://github.com/styleguidist/react-docgen-typescript/issues/434",target:"_blank",rel:"noopener noreferrer"}},[t._v("issue434"),s("OutboundLink")],1)]),t._v(" "),s("li",[t._v("不支持传入源码直接分析 ts 声明，只能直接扫描硬盘文件 "),s("a",{attrs:{href:"https://github.com/styleguidist/react-docgen-typescript/issues/439",target:"_blank",rel:"noopener noreferrer"}},[t._v("issue439"),s("OutboundLink")],1)])]),t._v(" "),s("p",[t._v("这三点对于需要提高编译性能、插件使用范围都是很大的问题。不过它的代码也非常值得参考，本文就是在阅读其源码过程中的一些分析和收获。")]),t._v(" "),s("h2",{attrs:{id:"代码分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#代码分析"}},[t._v("#")]),t._v(" 代码分析")]),t._v(" "),s("p",[t._v("简单流程如下\n"),s("img",{attrs:{src:"/yuque/0/2022/jpeg/139763/1656056355140-c730a9b5-3f44-413b-bd8a-c37bbac24348.jpeg",alt:""}}),t._v("\n用到了几个关键 ts compiler api。ts compiler 的 api 并没有公开文档，以下只是根据 RDT 的代码实际情况推测的含义：")]),t._v(" "),s("ol",[s("li",[t._v("getExportsOfModule: 获取 sourceFile 的导出模块")]),t._v(" "),s("li",[t._v("getAliasedSymbol: 获取实际定义的类型，忽略中间的引用/赋值关系 (Reference/PropertiesAssign)")]),t._v(" "),s("li",[t._v("type.getCallSignatures()  函数式组件通过这个 api 获取到调用函数签名")]),t._v(" "),s("li",[t._v("sig.getParameters();  通过签名获取参数类型")]),t._v(" "),s("li",[t._v("type.getConstructSignatures();  获取 (React) Class 的构造类型签名")]),t._v(" "),s("li",[t._v("sig.getReturnType(); 通过构造类型签名获取到实体类型")]),t._v(" "),s("li",[t._v("instanceType.getProperty('props');  通过实体类型获取它的 props 属性的类型")]),t._v(" "),s("li",[t._v("checker.getTypeOfSymbolAtLocation()； 使用 checker 获取 Props 的实际类型")]),t._v(" "),s("li",[t._v("symbol.getApparentProperties;  获取 symbol 的显性类型")]),t._v(" "),s("li",[t._v("symbol.isUnionOrIntersection；判断类型是否是 联合 类型")]),t._v(" "),s("li",[t._v("checker.getAllPossiblePropertiesOfTypes;  获取全部属性")]),t._v(" "),s("li",[t._v("type.getConstraint   获取泛型类型")])]),t._v(" "),s("p",[t._v("通过这些关键 api  及流程图，大概能了解 RDT 的工作原理了：")]),t._v(" "),s("ol",[s("li",[t._v("将文件路径传递给 ts.createPropgram，得到对应的 checker / program")]),t._v(" "),s("li",[t._v("获取 sourceFile 的所有导出，判断导出类型是否是 FC / ReactClass 组件，这里有个白名单类型用于确定是不是 React 组件，内置了 'Stateless', 'StyledComponentClass', 'StyledComponent', 'FunctionComponent', 'StatelessComponent', 'ForwardRefExoticComponent' 这些，也可以通过参数在外部传进来")]),t._v(" "),s("li",[t._v("根据组件类型，尝试从函数���参或者 Class 实体类型的 props，得到 props 的类型符号")]),t._v(" "),s("li",[t._v("获取 props 符号的类型，先排除它是泛型 / 联合类型")]),t._v(" "),s("li",[t._v("到这步已经确定此类型一定是 { a, b ,c  } 这样的结构")]),t._v(" "),s("li",[t._v("遍历第一层属性的类型")])]),t._v(" "),s("p",[t._v("从以上流程，可以得到两个重要信息：")]),t._v(" "),s("ol",[s("li",[t._v("只会在文件里找到特定范式的组件。如果是一些高阶组件或者它无法判定是不是 React 组件的，它会直接忽略；所以这个 issue 提的它从根本上就不支持 "),s("a",{attrs:{href:"https://github.com/styleguidist/react-docgen-typescript/issues/434",target:"_blank",rel:"noopener noreferrer"}},[t._v("issue434"),s("OutboundLink")],1)]),t._v(" "),s("li",[t._v("props 只遍历一层，并且类型不能是字面量类型/联合类型，所以这个 "),s("a",{attrs:{href:"https://github.com/styleguidist/react-docgen-typescript/issues/202",target:"_blank",rel:"noopener noreferrer"}},[t._v("issue202"),s("OutboundLink")],1),t._v(" 也不会在它的支持范围里")])]),t._v(" "),s("h2",{attrs:{id:"部分代码截图说明"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#部分代码截图说明"}},[t._v("#")]),t._v(" 部分代码截图说明")]),t._v(" "),s("p",[t._v("截图这段代码的功能：识别代码块如果是一个 memo(comp) ，或者 forwardRef(comp) ，首先判断表达式的 symbol 名称是否是 memo/forward，其次获取 valueDeclaration，断言它是一个 expression ，用人话说也就是预期此代码块是个函数调用表达式，同时调用的函数名应该是 memo 或者 forward。最后通过 函数(expression） 的 ast 取得函数调用的第一个参数，把参数交给 checker.getSymbolAtLocation，进而得到真实的 FC 组件。\n"),s("img",{attrs:{src:"/yuque/0/2022/png/139763/1656074581970-83ba6a15-4358-4823-b8de-85456546f1c4.png",alt:"image.png"}}),t._v("\n这段代码功能清晰逻辑简单，比较有代表性，事实上 react-docgen-typescript 大部分代码逻辑都是这个风格：推测一个范式 -> 如果符合，取得需要的 symbol -> symbol 再推测是否是特定范式 -> 以此推断下一个范式 -> 得到想要的类型声明结构 -> 使用 SyntaxKind 得到具体类型 -> 组装成描述结构。\n这也是为什么有些写法可能会出问题的原因，例如项目里没有安装 react，使用了 preact，或者 tsconfig 使用的 jsx mode 是 react-jsx 或者 jsx 模式，拿到的 symbol  name 可能并非代码里描述的名字，就会推算失败，从而无法得出正确的解析结果。或者写了一些很绕的逻辑，并不在它这个范式里，例如  HOC，或者根本没有声明是个 FC，也得不到正确解析结果。")]),t._v(" "),s("h2",{attrs:{id:"compiler-host"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#compiler-host"}},[t._v("#")]),t._v(" compiler host")]),t._v(" "),s("p",[t._v("ts.createProgram 的第三个参数是 compiler host，负责 ts 编译器的 IO 逻辑，也就是说除了这个 Host 以外，ts 的核心程序都只做语法分析，并不强依赖于文件系统，文件 IO 、额外库文件读取都交由 compiler host 来实现。基于这个能力，可以为 ts compiler 在浏览器环境运行提供了基础，事实上 "),s("a",{attrs:{href:"https://ts-ast-viewer.com/",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://ts-ast-viewer.com/"),s("OutboundLink")],1),t._v(" 等站点也都是基于这一能力的。而我们平时用到这一工具，其实更多是在 webpack-loader 环境，构造内存文件系统实现 sourcecode-ast 的转化。可惜的是，react-docgen-typescript 并没有实现这一能力。\n为什么需要 compiler host ?  常规理解应该就是对 source code 做 ast 分析就好了，顶多就读个 tsconfig.json，那需要一个跟文件系统有关的 host 做什么？其实从里面的一个 api 就看可以看出来："),s("code",[t._v("getTypeOfSymbolAtLocation")]),t._v(".\n当有 compiler host 的时候，如果程序中遇到  "),s("code",[t._v("const Comp: React.FC")]),t._v("，会看到：\n"),s("img",{attrs:{src:"/yuque/0/2022/png/139763/1656214707975-71993509-294e-4a75-bf70-8b9bd9037dcf.png",alt:"image.png"}}),t._v("\n实际上就是通过 host 的 getSourceFile 进一步读取到了 @types/react/index.d.ts 实际声明的位置，这里自然也就涉及到了文件系统。")]),t._v(" "),s("p",[t._v("基于这个 Host ，我可以写个简单的 wrap，让 ts compiler host 的读写文件做了接口级的缓存，让 ts 的 IO 更高效：")]),t._v(" "),s("div",{staticClass:"language-typescript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-typescript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 参数 hash 化")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashCode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" chr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" hash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    chr   "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("string")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("charCodeAt")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    hash  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<<")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v(" hash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" chr"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    hash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Convert to 32bit integer")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" hash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/** 相同的参数直接返回上次的请求值 */")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("cacheFuncByParams")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fn"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" cached "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    process"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("log "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("console")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("log")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" paramHash "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("hashCode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("toString")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("JSON")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("stringify")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("a"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("cached"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("paramHash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      cached"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("paramHash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("fn")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("...")]),t._v("args"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" cached"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("paramHash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" compilerHost "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getSourceFile")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" fileName "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFile")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fileName"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?.")]),t._v("sourceFile"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getDefaultLibFileName")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" opts "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("join")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("require")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("resolve")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'typescript'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token template-string"}},[s("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("../")]),s("span",{pre:!0,attrs:{class:"token interpolation"}},[s("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("${")]),t._v("ts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getDefaultLibFileName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("opts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token interpolation-punctuation punctuation"}},[t._v("}")])]),s("span",{pre:!0,attrs:{class:"token template-punctuation string"}},[t._v("`")])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("writeFile")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* pass */")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getCurrentDirectory")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getDirectories")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("fileExists")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" filename "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" fs"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("existsSync")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("readFile")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" fileName "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getFile")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fileName"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("code"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getCanonicalFileName")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" fileName "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("useCaseSensitiveFileNames "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" fileName "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" fileName"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("toLowerCase")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("useCaseSensitiveFileNames")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" ts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("useCaseSensitiveFileNames"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getNewLine")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" ts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sys"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("newLine"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function-variable function"}},[t._v("getEnvironmentVariable")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nObject"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("keys")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("compilerHost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("forEach")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" compilerHost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'function'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    compilerHost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("cacheFuncByParams")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("compilerHost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 之后在扫描 ts 预发树时，就可以直接这样使用, 实现库文件不用二次读取")]),t._v("\nts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createProgram")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("files"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" options"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" compilerHost"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("h2",{attrs:{id:"🐂🍺的地方"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#🐂🍺的地方"}},[t._v("#")]),t._v(" 🐂🍺的地方")]),t._v(" "),s("p",[t._v("typescript 官网 compiler 是几乎没有文档的，搜寻了网上的，除了官网的一个 "),s("a",{attrs:{href:"https://github.com/Microsoft/TypeScript/wiki/Using-the-Compiler-API#a-minimal-compiler",target:"_blank",rel:"noopener noreferrer"}},[t._v("wiki"),s("OutboundLink")],1),t._v(" , 还有一个民间写的"),s("a",{attrs:{href:"https://jkchao.github.io/typescript-book-chinese/compiler/program.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("编辑器文档"),s("OutboundLink")],1),t._v(" 就再找不到其他的了。剩下的都是一些 low得不行的"),s("a",{attrs:{href:"https://juejin.cn/post/6844904177286512653",target:"_blank",rel:"noopener noreferrer"}},[t._v("初级文档"),s("OutboundLink")],1),t._v("，或者是从官方 wiki 拷贝过来的"),s("a",{attrs:{href:"https://learning-notes.mistermicheels.com/javascript/typescript/compiler-api/",target:"_blank",rel:"noopener noreferrer"}},[t._v("只言片语"),s("OutboundLink")],1),t._v("。像 react-docgen-typescript 使用得这么深的 api ，真不知道是怎么做到的。不过通过这些分析，看起来 ts-compiler api 更多的使用场景其实是 ts 转 js 构建、IDE 的 LSP ，而不是用来做一般的代码提取。\n以往我写过一个 "),s("a",{attrs:{href:"https://github.com/javaxiu/api-loader/",target:"_blank",rel:"noopener noreferrer"}},[t._v("api-loader "),s("OutboundLink")],1),t._v(", 也是基于 ast 将 typescript 翻译成类似 json schema 和 ajax 请求代码的工具，但是也都是基于 "),s("a",{attrs:{href:"https://ts-ast-viewer.com/",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://ts-ast-viewer.com/"),s("OutboundLink")],1),t._v(" ，根据 ast 一层层写 node-walker 来推测信息翻译代码的，并没有 RDT 这么高阶的使用 compiler  api ，很值得学习。不过 api-loader 也不合适大量用 ts compiler api 像 react-docgen-typescript 一样去用范式推断来实现，因为 api-loader 的思路更多是原地翻译，感兴趣的可以试用一下 api-loader 。\nreact-docgen-typescript 不支持的那些 feature ，我正在考虑自己来实现一个，但是也正如 react-docgen-typescript 这些限制并不是因为它的设计不够通用，而是 ts-ast 本身就具备很多灵活性，而解析目标又是个确定性的，只能枚举一定量的范式来支持。但是我至少会解决这两个问题：")]),t._v(" "),s("ol",[s("li",[t._v("不支持深层嵌套的结构")]),t._v(" "),s("li",[t._v("强依赖 file-system ，导致无法做成 webpack loader 等 JIT 工具")])]),t._v(" "),s("h2",{attrs:{id:"有趣的效果"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#有趣的效果"}},[t._v("#")]),t._v(" 有趣的效果")]),t._v(" "),s("p",[t._v("vscode 的 typescript 类型识别流程大致是  ts ast -> ts symbol -> ts-lsp -> vscode 界面提示。下面这种复杂结构：泛型 + 合并类型 + 循环(Pick 是基于 in 语法）+ 类型推断，vscode 都可以给出正确的类型提示：\n"),s("img",{attrs:{src:"/yuque/0/2022/png/139763/1661829054014-e3ec63c0-9789-4685-92d6-38cc73758240.png",alt:"image.png"}}),t._v("\n这个效果的本质原理是每一个类型都是一个 ts 里面的 Symbol ，Symbol 在 ts 的概念里，与文件路径、类型名称无关，就是一个通过 ts program 语法解析得到的一个组合模式的类型符号，它可以是一个 type / interface /class / 甚至是一个匿名类型、infer 等。Symbol 背后是层层文件查找，在使用到特定的 Symbol 的时候会调用文件系统读取到其真实类型，如图的这种例子，如果 Symbol 是一个 Object 类型，则通过类似 "),s("code",[t._v("getApparentProperties")]),t._v("这样的方法可以查询到经过了 extends、& 、in 、alias、typeof js 类型转换、infer 类型推断 等各种骚操作最终合并得到的类型列表。因此 vscode 才能识别到这么复杂的类型结构。而根据这个原理，实际上我们完全可以复用其 ast 解析器，把上面这个复杂的类型给解析出来，得到如下结果：\n"),s("img",{attrs:{src:"/yuque/0/2022/png/139763/1661829435763-03335a4e-b673-4ccf-b537-9f1af1319a08.png",alt:"image.png"}}),t._v("\n这里为了方便截图展示，把几个类型都写在一个文件里，把它们拆开放在不同的文件也是一样的解析效果。当然，这个效果主要还是在 react-docgen-typescript 的基础上，补充了一些递归查找的代码实现的。借此可以做的事情可以远超基础的仅针对当前文件的代码做 ast 解析可以做得到的效果。\n像截图中选中的区域，是目前我写的递归解析尚未完善的地方，这里应该可以继续根据解析 symbol 背后的类型。ts 世界的类型实在太复杂，日常看到的 union 、infer、interface、literal 等，仅仅只是水面之上的冰山，要全部处理出来不是不可以，只是成本很高，且效果暂时用不着")])])}),[],!1,null,null,null);s.default=e.exports}}]);